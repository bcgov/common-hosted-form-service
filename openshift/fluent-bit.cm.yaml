---
apiVersion: v1
kind: Template
labels:
  app: "${APP_NAME}-${JOB_NAME}"
  template: "${REPO_NAME}-app-dc-template"
metadata:
  name: "${REPO_NAME}-app-dc"
objects:
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: fluent-bit-config
      namespace: ${NAMESPACE}
    data:
      # Configuration files: server, input, filters and output
      fluent-bit.conf: |
        [SERVICE]
          Flush         5
          Daemon        Off
          # define the log format (see additional config map key/value)
          Parsers_File  parsers.conf
          Log_Level     info
          HTTP_Server   On
          HTTP_Listen   0.0.0.0
          HTTP_Port     2020

        # read logs from app log file
        [INPUT]
          # get logs from file written by node app
          Name  tail
          Path  /var/log/*
          Tag   app

        # exclude kube probe logs from app logs
        [FILTER]
          # exclude kube probe logs from app logs
          name     grep
          match    app
          Exclude  agent kube-probe*

        # parse app record a JSON
        [FILTER]
          name          parser
          match         app
          Key_Name      log
          Parser        json
          Reserve_Data  On
          Preserve_Key  On

        # modify record to include more key/value pairs
        [FILTER]
          name    record_modifier
          match   app
          # add pod name
          Record  hostname ${HOSTNAME}
          # add productname (eg: 'chefs')
          Record  product ${APP_NAME}
          # add namespace
          Record  namespace ${NAMESPACE}

        # append tag corresponding to log level
        [FILTER]
          Name          rewrite_tag
          Match         app
          Rule          $level ([a-zA-Z]*)$ $TAG.$level true
          Emitter_Name  re_emitted

        # map app.http logs to ECS format
        [FILTER]
          Name    lua
          Match   app.http
          script  script.lua
          call    ecsMap

        # send records tagged with just 'app' to external fluentd service endpoint
        [OUTPUT]
          Name    http
          Match   app
          Host    ${LOGGING_HOST_NAME}
          Port    80
          Format  json
          # the URI becomes the Tag available in fluentd
          URI     /app
          # we can also send tag as a header
          #header_tag  app

        # send http level logs (with tag: 'app.http') to AWS Opensearch
        # [OUTPUT]
        #   Name http
        #   Match app.http

        [OUTPUT]
          # show all fluent-bit logs to standard output
          Name   stdout
          Match  *

      parsers.conf: |
        [PARSER]
          Name             json
          Format           json
          Time_Key         time
          Time_Format      %Y-%m-%dT%H:%M:%S %z
          Decode_Field_as  escaped_utf8 log do_next
          Decode_Field_as  json log

      script.lua: |
        --[[
          returns: code, timestamp, record
          where:
          - code     : -1 record must be deleted
                        0 record not modified, keep the original
                        1 record was modified, replace timestamp and record.
                        2 record was modified, replace record and keep timestamp.
          - timestamp: Unix timestamp with precision (double)
          - record   : Table with multiple key/val
        ]]

        -- Compose a new JSON map and report it
        function ecsMap(tag, timestamp, record)
          new_record = {
            ["@timestamp"] = record["timestamp"],
            ["azp"] = record["azp"],
            ["ecs"] = {
              ["version"] = "1.5.0"
            },
            ["event"] = {
              ["original"] = record["log"],
              ["module"] = "express",
              ["dataset"] = "express.access",
              ["kind"] = "event",
              ["categoty"] = {"network", "web"},
              ["type"] = "access"
            },
            ["host"] = {
              ["hostname"] = record["hostname"],
              ["namespace"] = record["namespace"]
            },
            ["http"] = {
              ["request"] = {
                ["method"] = record["method"]
              },
              ["response"] = {
                ["body"] = {
                  ["bytes"] = record["contentLength"]
                },
                ["status_code"] = record["statusCode"],
                ["time"] = record["responseTime"]
              },
              ["version"] = record["httpVersion"]
            },
            ["query"] = record["query"],
            ["message"] = record["message"],
            ["product"] = record["product"],
            ["source"] = {
              ["address"] = record["todo"],
              ["ip"] = record["todo"]
            },
            ["url"] = {
              ["original"] = record["path"]
            },
            ["user_agent"] = {
              ["original"] = record["userAgent"]
            }
          }

          return 2, timestamp, new_record
        end

parameters:
  - name: APP_NAME
    description: Application name
    displayName: Application name
    required: true
  - name: REPO_NAME
    description: Application repository name
    displayName: Repository Name
    required: true
  - name: JOB_NAME
    description: Job identifier (i.e. 'pr-5' OR 'master')
    displayName: Job Branch Name
    required: true
    value: master
  - name: NAMESPACE
    description: Target namespace reference (i.e. 'b160aa-dev')
    displayName: Target Namespace
    required: true
  - name: LOGGING_HOST_NAME
    description: The hostname of our FLuentd service running further down the monitoring pipeline
    displayName: Logging host name
    required: true
